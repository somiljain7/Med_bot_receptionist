{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\conda\\envs\\GEN_AI_T1\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import models,QdrantClient\n",
    "import numpy\n",
    "#pip install 'numpy<2'\n",
    "import time\n",
    "import threading\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import spacy\n",
    "import random\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    #tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\") #for a different NER \n",
    "    #model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\") #for a different NER\n",
    "    ref_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    #nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer) #for a different NER\n",
    "    return ref_model,nlp\n",
    "\n",
    "def location_ner(nlp,res):\n",
    "    doc = nlp(res)\n",
    "    # Extract entities recognized as locations (GPE: Geopolitical Entities, LOC: Non-GPE locations)\n",
    "    locations = [ent.text for ent in doc.ents if ent.label_ in ['GPE', 'LOC']]\n",
    "    if locations:\n",
    "        return ', '.join(locations)\n",
    "    else:\n",
    "        return 0\n",
    "    #\"I didn't understand your response. Could you please provide the area that you are located in right now?\"\n",
    "    \n",
    "def is_semantically_related(ref_model,sentence, reference_sentences, threshold=0.7):\n",
    "    sentence_embedding = ref_model.encode(sentence, convert_to_tensor=True)\n",
    "    for ref_sentence in reference_sentences:\n",
    "        ref_embedding = ref_model.encode(ref_sentence, convert_to_tensor=True)\n",
    "        similarity = util.pytorch_cos_sim(sentence_embedding, ref_embedding)\n",
    "        if similarity.item() > threshold:\n",
    "            return True, similarity.item()\n",
    "\n",
    "    return False, 0\n",
    "\n",
    "def relevance_check(ref_model,user_sentence): \n",
    "    reference_sentences_set1 = [\"too late\", \"arrive too late\",\"i am panicing\", \"won't make it in time\", \"delayed\", \"take too long\", \"not soon enough\", \"we can't wait\", \"need help immediately\", \"time-sensitive\", \"urgent\" ,\"The doctor will not arrive in time.\", \"I am worried the doctor will be too late.\"]\n",
    "    reference_sentences_set2 = [\"No Thank you\",'Thanks for all the help','Thanks']\n",
    "    is_related_1, similarity_score_1 = is_semantically_related(ref_model,user_sentence, reference_sentences=reference_sentences_set1)\n",
    "    is_related_2, similarity_score_2 = is_semantically_related(ref_model,user_sentence, reference_sentences=reference_sentences_set2)\n",
    "    if is_related_1 or is_related_2:\n",
    "        if similarity_score_1 > similarity_score_2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 2\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def vector_search(qdrant,encoder,x):\n",
    "    # Search within a Vector database \n",
    "    #args:\n",
    "    #qdrant: object of QdrantClient\n",
    "    #encoder:  encoder for semantic similarity\n",
    "    #x: sentence for calculating semantic similarity with records \n",
    "    hits = qdrant.search(\n",
    "        collection_name='Clinical',\n",
    "        query_vector=encoder.encode(x).tolist(),\n",
    "        limit=1\n",
    "    )\n",
    "    for hit in hits:\n",
    "        return (hit.payload)#,'score:',hit.score)\n",
    "\n",
    "\n",
    "def vector_database_init():\n",
    "    # initializing Qdrant client at port 6333\n",
    "    qdrant = QdrantClient(\n",
    "        host='localhost',\n",
    "        port=6333\n",
    "    )\n",
    "    return qdrant\n",
    "\n",
    "\n",
    "def process(symptoms):\n",
    "    # Generating the Output of vector search\n",
    "    print(\"\\nProcessing the emergency report...\")\n",
    "    time.sleep(15)  # Simulate processing time\n",
    "    encoder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    qdrant=vector_database_init()\n",
    "    llm_output = f\"The analysis indicates a possible condition based on the symptoms: {vector_search(qdrant,encoder,symptoms)}\"\n",
    "    return llm_output\n",
    "\n",
    "\n",
    "def generate_random_eta():\n",
    "    random_seconds = random.randint(60, 7200)\n",
    "    eta = datetime.timedelta(seconds=random_seconds)\n",
    "    total_seconds = int(eta.total_seconds())\n",
    "    hours = total_seconds // 3600\n",
    "    minutes = (total_seconds % 3600) // 60\n",
    "    seconds = total_seconds % 60\n",
    "    formatted_eta = f\"{hours:02}:{minutes:02}:{seconds:02}\"\n",
    "    return formatted_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! My name is RIYA and i work as a receptionist for Dr. Adrin. How can I help you today?\n",
      "\n",
      "RIYA : Please choose one of the following options:\n",
      "1. Send a message\n",
      "2. Report an emergency\n",
      "\n",
      "RIYA : You selected 'Report an emergency'.\n",
      "User: My friend is unable to breathe\n",
      "\n",
      "Processing the emergency report...\n",
      "RIYA : Please hold just a sec\n",
      "User: 202, raunak vihar , 3/1 , Old Palasia , Indore , India\n",
      "RIYA : Location '202, raunak vihar , 3/1 , Old Palasia , Indore , India' received.  Dr. Adrin will be coming to their location immediately. ETA:01:49:18\n",
      "\n",
      "RIYA :  Processing complete. Here is the analysis from our system:\n",
      "The analysis indicates a possible condition based on the symptoms: {'name': 'Carbon Monoxide Poisoning', 'remedy': 'Move the person to fresh air immediately, call emergency services, and administer oxygen if trained to do so.'}\n",
      "User: ETA is too late  . arrival of dr too late\n",
      "RIYA : I understand that you are worried that Dr. Adrin will arrive too late, meanwhile we would suggest that you follow following remedy:The analysis indicates a possible condition based on the symptoms: {'name': 'Carbon Monoxide Poisoning', 'remedy': 'Move the person to fresh air immediately, call emergency services, and administer oxygen if trained to do so.'} \n",
      "\n",
      "RIYA : Thank you for using the service. Stay safe!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ref_model,nlp=model_init()\n",
    "\n",
    "print(\"Hello! My name is RIYA and i work as a receptionist for Dr. Adrin. How can I help you today?\")\n",
    "while True:\n",
    "    print(\"\\nRIYA : Please choose one of the following options:\")\n",
    "    print(\"1. Send a message\")\n",
    "    print(\"2. Report an emergency\")\n",
    "    user_choice = input(\"Enter 1 or 2: \").strip()\n",
    "    if user_choice == \"1\":\n",
    "        message = input(\"\\nPlease enter the message you want to send: \")\n",
    "        print( \"RIYA :Thanks for the message, we will forward it to Dr. Adrin\")\n",
    "        break\n",
    "    elif user_choice == \"2\":\n",
    "        print(\"\\nRIYA : You selected 'Report an emergency'.\")\n",
    "        symptoms = input(\"Please describe the symptoms: \")\n",
    "        print(f\"User: {symptoms}\")\n",
    "        llm_output = []\n",
    "        def process_and_store():\n",
    "            result = process(symptoms)\n",
    "            llm_output.append(result)  # Store the semantic similarity search output in a list\n",
    "        processing_thread = threading.Thread(target=process_and_store)\n",
    "        processing_thread.start()\n",
    "\n",
    "        print(\"RIYA : Please hold just a sec\")    \n",
    "            # Simultaneously ask for location\n",
    "        location = input(\"RIYA : I am checking what you should do immediately, meanwhile, can you tell me which area are you located right now?\")\n",
    "        ETA=generate_random_eta()\n",
    "        print(f\"User: {location}\")\n",
    "        if location_ner(nlp,location)!=0:\n",
    "            print(f\"RIYA : Location '{location}' received.  Dr. Adrin will be coming to their location immediately. ETA:{ETA}\")\n",
    "        else: \n",
    "            location=input(\"I don't understand that and could you please repeat the area you are located right now (in proper format)? \")\n",
    "            print(f\"User: {location}\")\n",
    "            if(location_ner(nlp,location)==0):\n",
    "                print(\"RIYA : I donâ€™t understand that and unable to fetch your location ,could you please try again later .\")\n",
    "                exit()\n",
    "            else:\n",
    "                print(f\"RIYA : Location '{location}' received.  Dr. Adrin will be coming to their location immediately. ETA:{ETA}\")\n",
    "        processing_thread.join()\n",
    "            \n",
    "            # Print the semantic similarity search output after location input\n",
    "        print(\"\\nRIYA :  Processing complete. Here is the analysis from our system:\")\n",
    "        print(llm_output[0])  # Access the first (and only) element in the list\n",
    "        response = input(\"Do you have anything else to ask ?\") \n",
    "        print(f\"User: {response}\")\n",
    "        res_rev=relevance_check(ref_model,response)\n",
    "        if res_rev==1:\n",
    "            print(f\"RIYA : I understand that you are worried that Dr. Adrin will arrive too late, meanwhile we would suggest that you follow following remedy:{llm_output[0]} \\n\"  )\n",
    "        elif res_rev==2:\n",
    "            print(f\"RIYA : Thank you , Dr. Adrin will be with you shortly \"  )\n",
    "        else:\n",
    "            print(\"RIYA : I don't understand that but Donâ€™t worry, please follow the steps, Dr. Adrin will be with you shortly\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"\\nRIYA : Invalid choice. Please enter '1' to send a message or '2' to report an emergency.\")\n",
    "    \n",
    "print(\"\\nRIYA : Thank you for using the service. Stay safe!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GEN_AI_T1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
